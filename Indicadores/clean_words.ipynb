{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_indicators.txt\") as f:\n",
    "    words = f.readlines()"
   ]
  },
  {
   "source": [
    "## remove clue words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'clue_words_pt'\n",
    "cluewords = list()\n",
    "for file_name in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    with open(file_path) as f:\n",
    "        cluewords.extend([w.rstrip().lower().replace(' ', '_') for w in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w.rstrip().lower().replace(' ', '_') for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "all cluewords in wordw?  True\n#words - cluewords = 625 - 84 = 541\n"
     ]
    }
   ],
   "source": [
    "print('all cluewords in wordw? ', all([(w in words) for w in cluewords]))\n",
    "print(f'#words - cluewords = {len(words)} - {len(cluewords)} = {len(words) - len(cluewords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "for w in cluewords:\n",
    "    words.remove(w)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quantidade original 541\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade original', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quantidade após retirar duplicatas: 374\n"
     ]
    }
   ],
   "source": [
    "words = list(set(words))\n",
    "print('Quantidade após retirar duplicatas:', len(words))"
   ]
  },
  {
   "source": [
    "## Stopwords que estão na lista de indicadores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "preprocessando"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_terms = [\n",
    "    \"as_explicações_e_exemplo_acima_mostram_que\",\n",
    "    \"deliciosamente\",\n",
    "    \"virtualmente\",\n",
    "    \"pesquisadores_descobriram_que\"\n",
    "    \"ao_contrario\",\n",
    "    \"ate\",\n",
    "    \"ate_mesmo\",\n",
    "    \"convém_enaltecer_o/a\",\n",
    "    \"pelo_contrario\",\n",
    "    \"porem\",\n",
    "    \"tao\",\n",
    "    \"urge_que\"\n",
    "]\n",
    "not_exist_in_corpus = [\n",
    "    'a_essa_linha_de_raciocínio',\n",
    "    'a_fim_de_que',\n",
    "    'acerca_dessa_lógica',\n",
    "    'acho_que_a_visão_é',\n",
    "    'acredito_firmemente_nisso',\n",
    "    'acredito_fortemente_nisso',\n",
    "    'além_dessas_vantagens',\n",
    "    'analisando_as_duas_visões',\n",
    "    'aponta_para_as_conclusões',\n",
    "    'com_base_em_algumas_razões',\n",
    "    'considerando_as_duas_coisas',\n",
    "    'considerando_este_assunto',\n",
    "    'contrariamente_a_essa_lógica',\n",
    "    'da_explicação_acima',\n",
    "    'de_acordo_com',\n",
    "    'deduzo_disso',\n",
    "    'defendo_fortemente_isso',\n",
    "    'deve_também_anote',\n",
    "    'em_contra_ponto',\n",
    "    'em_decorrência_de',\n",
    "    'em_vez_de',\n",
    "    'este_resultará',\n",
    "    'faz-se_urgente_que',\n",
    "    'isso_pode_ser_visto_de',\n",
    "    'levando_em_conta_esse_fato',\n",
    "    'levando_à_consequência',\n",
    "    'minha_conclusão',\n",
    "    'minha_profunda_convicção',\n",
    "    'nesse_contexto_relativo_a',\n",
    "    'nesse_tocante',\n",
    "    'no_intuito_de',\n",
    "    'no_que_diz_respeito_a',\n",
    "    'não_concordo_com_esta_afirmação',\n",
    "    'não_mais_que',\n",
    "    'o_ponto_que_estou_tentando_fazer',\n",
    "    'outra_instância_é',\n",
    "    'outro_aspecto_relevante_é_que',\n",
    "    'para_o_meu_modo_de_pensar',\n",
    "    'para_oferecer_uma_instância',\n",
    "    'pelas_razões_mencionadas_acima',\n",
    "    'por_mais_que',\n",
    "    'por_uma_questão_de_fato',\n",
    "    'preferiria_dizer',\n",
    "    'reafirmaria_minha_posição_de_que',\n",
    "    'recomendo_fortemente',\n",
    "    'resta_pouca_dúvida',\n",
    "    'segue_isso',\n",
    "    'sob_diferente_viés',\n",
    "    'sob_diferente_ótica',\n",
    "    'sob_esse_viés',\n",
    "    'tendo_em_vista_que',\n",
    "    'teria_de_argumentar_que',\n",
    "    'todas_as_coisas_consideradas',\n",
    "    'torna-se_imprescindível_esclarecer_que',\n",
    "    'torna-se_imprescindível_que',\n",
    "    'uma_vez_que_a_evidência_é',\n",
    "    'você_pode_concluir_disso',\n",
    "    'vou_resumir_dizendo',\n",
    "    'à_luz_dos_fatos_descritos_acima',\n",
    "    'é_conveniente_destacar_que'\n",
    "]\n",
    "with open('general_indicators.txt') as f:\n",
    "    general_terms = [w.rstrip() for w in f.readlines()]\n",
    "\n",
    "with open(\"../data/stop_words_preprocessed.txt\") as f:\n",
    "    stopwords = [w.rstrip() for w in f.readlines()]\n",
    "\n",
    "def clean(word):\n",
    "    if word.startswith(\"eu_\"):\n",
    "        return word[3:]\n",
    "    if word == \"do_contrario\":\n",
    "        return \"do_contrário\"\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [clean(w) for w in words if w not in remove_terms and w not in stopwords]"
   ]
  },
  {
   "source": [
    "salva possíveis indicadores gerais (unigramas)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = [w for w in words if '_' not in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unigrams_indicators_to_analyse.txt', 'w') as f:\n",
    "    for w in unigrams:\n",
    "        f.write(w + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in words if w not in (not_exist_in_corpus + general_terms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_indicators_woclue.txt', 'w') as f:\n",
    "    for w in sorted(words):\n",
    "        f.write(w + '\\n')"
   ]
  },
  {
   "source": [
    "## Preprocessando por fonte de lexicon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all files from a folder\n",
    "folders = [\n",
    "    'brasil_escola',\n",
    "    'clue_words_pt',\n",
    "    'acrobata_das_letras',\n",
    "    'mundo_educacao',\n",
    "    'Subjetivity_lexicon',\n",
    "    'PersuativeEssays_UKP',\n",
    "    '2020_Jonathan'\n",
    "    ]\n",
    "\n",
    "for folder in folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        words = list()\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(file_path) as f:\n",
    "            words = [w.rstrip().lower().replace(' ', '_') for w in f.readlines()]\n",
    "            words = [clean(w) for w in words if w not in remove_terms and w not in stopwords]\n",
    "            words = [w for w in words if w not in (not_exist_in_corpus + general_terms)]\n",
    "            words = list(set(words))\n",
    "        with open(file_path, 'w') as f:\n",
    "            for w in sorted(words):\n",
    "                f.write(w + '\\n')"
   ]
  },
  {
   "source": [
    "pega palavras marcadas **manualmente (-)** como duvidosas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['agora', 'até', 'caso', 'como', 'consoante', 'e', 'geral', 'mais', 'mesmo', 'meus_sentimentos', 'pesquisadores_descobriram_que', 'pessoalmente', 'primeiro', 'se', 'segundo', 'último']\n"
     ]
    }
   ],
   "source": [
    "with open(\"preprocessed_indicators copy.txt\") as f:\n",
    "    preprocessed_words = f.readlines()\n",
    "preprocessed_words = [w[:len(w) -2] for w in preprocessed_words if w.rstrip().endswith('-')]\n",
    "print(preprocessed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}